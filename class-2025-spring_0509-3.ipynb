{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kwb425/class-2025-spring/blob/main/class-2025-spring_0509-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_QBPnrEWzH9"
   },
   "outputs": [],
   "source": [
    "!pip install seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot the current state of the EM algorithm\n",
    "def plot_em_2d(red_mean, red_cov, blue_mean, blue_cov, red_dots, blue_dots, step):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot the points\n",
    "    plt.scatter(red_dots[:, 0], red_dots[:, 1], c='red', label='Red cluster points')\n",
    "    plt.scatter(blue_dots[:, 0], blue_dots[:, 1], c='blue', label='Blue cluster points')\n",
    "\n",
    "    # Plot the Gaussian distributions for red cluster\n",
    "    red_ellipse = Ellipse(\n",
    "        xy=red_mean,\n",
    "        width=2 * np.sqrt(red_cov[0, 0]),\n",
    "        height=2 * np.sqrt(red_cov[1, 1]),\n",
    "        angle=np.rad2deg(np.arctan2(red_cov[1, 0], red_cov[0, 0])),\n",
    "        edgecolor='red',\n",
    "        fc='None',\n",
    "        lw=2,\n",
    "        label='Red contour'\n",
    "    )\n",
    "    plt.gca().add_patch(red_ellipse)\n",
    "\n",
    "    # Plot the Gaussian distributions for blue cluster\n",
    "    blue_ellipse = Ellipse(\n",
    "        xy=blue_mean,\n",
    "        width=2 * np.sqrt(blue_cov[0, 0]),\n",
    "        height=2 * np.sqrt(blue_cov[1, 1]),\n",
    "        angle=np.rad2deg(np.arctan2(blue_cov[1, 0], blue_cov[0, 0])),\n",
    "        edgecolor='blue',\n",
    "        fc='None',\n",
    "        lw=2,\n",
    "        label='Blue contour'\n",
    "    )\n",
    "    plt.gca().add_patch(blue_ellipse)\n",
    "\n",
    "    plt.title(f'EM Algorithm Step {step}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Generate 2D data\n",
    "np.random.seed(111)\n",
    "red_mean_2d = np.array([0, 0])\n",
    "blue_mean_2d = np.array([3, 3])  # Closer clusters for more overlap\n",
    "red_cov_2d = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "blue_cov_2d = np.array([[1.5, 0.3], [0.3, 1.5]])\n",
    "\n",
    "red_dots_2d = np.random.multivariate_normal(red_mean_2d, red_cov_2d, 100)\n",
    "blue_dots_2d = np.random.multivariate_normal(blue_mean_2d, blue_cov_2d, 100)\n",
    "purple_dots_2d = np.vstack((red_dots_2d, blue_dots_2d))\n",
    "\n",
    "# Initial guesses\n",
    "red_mean_guess_2d = np.array([5, 5])  # Far from true mean\n",
    "blue_mean_guess_2d = np.array([-5, -5])  # Far from true mean\n",
    "red_cov_guess_2d = np.array([[3, 0.5], [0.5, 3]])  # Random covariance\n",
    "blue_cov_guess_2d = np.array([[2, -0.3], [-0.3, 2]])  # Random covariance\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.3\n",
    "\n",
    "# EM algorithm for 2D data\n",
    "for step in range(20):  # Run for fewer steps to observe evolution\n",
    "    # E-step: calculate responsibilities\n",
    "    red_likelihoods = stats.multivariate_normal.pdf(purple_dots_2d, mean=red_mean_guess_2d, cov=red_cov_guess_2d)\n",
    "    blue_likelihoods = stats.multivariate_normal.pdf(purple_dots_2d, mean=blue_mean_guess_2d, cov=blue_cov_guess_2d)\n",
    "    normalizing_constant = red_likelihoods + blue_likelihoods\n",
    "    red_weights = red_likelihoods / normalizing_constant\n",
    "    blue_weights = blue_likelihoods / normalizing_constant\n",
    "\n",
    "    # Assign points to clusters based on maximum responsibility\n",
    "    red_cluster = purple_dots_2d[red_weights > blue_weights]\n",
    "    blue_cluster = purple_dots_2d[blue_weights >= red_weights]\n",
    "\n",
    "    # M-step: update parameters with learning rate\n",
    "    new_red_mean = np.sum(purple_dots_2d * red_weights[:, np.newaxis], axis=0) / np.sum(red_weights)\n",
    "    new_blue_mean = np.sum(purple_dots_2d * blue_weights[:, np.newaxis], axis=0) / np.sum(blue_weights)\n",
    "    new_red_cov = np.cov(purple_dots_2d.T, aweights=red_weights)\n",
    "    new_blue_cov = np.cov(purple_dots_2d.T, aweights=blue_weights)\n",
    "\n",
    "    red_mean_guess_2d = (1 - learning_rate) * red_mean_guess_2d + learning_rate * new_red_mean\n",
    "    blue_mean_guess_2d = (1 - learning_rate) * blue_mean_guess_2d + learning_rate * new_blue_mean\n",
    "    red_cov_guess_2d = (1 - learning_rate) * red_cov_guess_2d + learning_rate * new_red_cov\n",
    "    blue_cov_guess_2d = (1 - learning_rate) * blue_cov_guess_2d + learning_rate * new_blue_cov\n",
    "\n",
    "    # Plot the current state\n",
    "    plot_em_2d(red_mean_guess_2d, red_cov_guess_2d, blue_mean_guess_2d, blue_cov_guess_2d, red_cluster, blue_cluster, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualization of LR algorithm\n",
    "# Generate sample data\n",
    "np.random.seed(111)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Add bias term (intercept) to X\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Number of iterations\n",
    "n_iterations = 30\n",
    "\n",
    "# Perform gradient descent\n",
    "for iteration in range(n_iterations):\n",
    "\tgradients = 2/100 * X_b.T.dot(X_b.dot(theta) - y)\n",
    "\ttheta = theta - learning_rate * gradients\n",
    "\t\n",
    "\t# Plot the data and the regression line\n",
    "\tplt.plot(X, y, \"b.\")\n",
    "\tplt.plot(X, X_b.dot(theta), \"r-\", linewidth=2, label=f\"Step {iteration+1}\")\n",
    "\tplt.xlabel(\"X\")\n",
    "\tplt.ylabel(\"y\")\n",
    "\tplt.title(f\"Linear Regression Step {iteration+1}\")\n",
    "\tplt.legend()\n",
    "\tplt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUR6YB4o85f8Gwntxny0cj",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
